<!DOCTYPE html>
<html>
<head>
<style> </style>
<!-- Copyright 2023: Robert Wilkins, graduated from Newton North High School in 1984, in Massachusetts, USA -->

</head>

<body>


Do we really need experiments for comparing productivity across different work processes or across different software tools? <br>
Yeah you do. Biotechs and pharmaceutical firms waste millions of dollars every year because you don't experiment, you don't try out different things. Every clinical trial report has perhaps over 200 statistical tables. Every table requires several hundred lines of SAS code. This is so obviously a colossal waste of money. So yes, you absolutely need to run experiments. <br>
And don't get me started on data cleaning. That is so hugely labour intensive, and I can help with that too.
<br><br>
You cannot get higher productivity (and therefore lower long-term costs) without some tolerance for a modest amount of short term spending. <br>

Figuring out what works and what doesn't work requires at least a minimum of experimentation. That is why I recommend "workflow experiments" and I do have a few options for conducting such experiments quickly and at low cost. <br>

<br><br>
These experiments involve workers (or students, or high school graduates who receive a stipend to participate) using different software tools or work processes to clean data, do analyses, and publish statistical tables. Simpler experiments can compare individuals. More informative experiments can compare small groups - the groups operate independently, but within each group, the students share notes and help each other learn. Group-to-group comparison makes sense because computer programming is a group activity and coders often behave like tribes. However experiments that compare groups could be more expensive than simpler experiments with individuals. <br>

For medium size biotechs and large drug firms, such experiments are not at all expensive, and can save tens of millions of dollars. For smaller biotechs, there are ways to reduce the costs even further. Obviously, smaller firms can pool resources, saving a lot of money.  <br>

One possibility for saving money and doing experiments more quickly is to partner with academia. However you can also waste money if you are not aware of cultural obstacles in colleges and universities. <br>

While providing technical support for a machine learning group at a Boston area college, I asked a professor if any of the statistics professors had an interest in different statistical programming languages and how they impacted practical outcomes, including worker productivity. He responded that he knew of no professors or graduate students who had such interests. Actually, unfortunately, that response is quite common in academia. In academia, some research questions are "prestigious". Other research questions are important for economic reasons, including worker productivity. But they are not "prestigious", so people in academia ignore them. Just be aware of these obstacles in the beginning, because a partnership with academia requires a negotiation between the drug firm and the college. As senior corporate executives, you do have some influence. Can you persuade some academics to rethink what is prestigious and what is not prestigious?<br><br>








<br><br><br>
What are some other less expensive ways for conducting workflow experiments? <br><br>

Conduct experiments that compare individual programmers, and do not compare group-to-group. Sometimes (not always) these experiments can be sufficiently informative, and less expensive. <br><br>

Conduct experiments where the product design (and software implementation) has already been completed and in part tested. A tool is ready for the students in the workflow experiment to play around with. <br>
I have one such option, ready for testing, contact me. <br>
These options are not always available, but when they are, paying for the workflow experiment mainly consists of paying for the students' time (also the hardware). <br><br>

Conduct experiments with high school graduates who have well above math grades. Why does this save you money? The learning curve is quicker, the experiment is shorter, perhaps less than six weeks, and hence the experiment is much cheaper. <br><br>

Conduct experiments where the tool or work process is easy to learn quickly. <br><br>
This can be a bit tricky if the tool you are currently using (and want to compare to another newer tool) has a very long learning curve. For example, using the SAS language to produce complex statistical tables of the sort you see in a clinical study report. A worker with less than two years experience probably cannot do this, but the workflow experiments I am recommending to you can be done in less than four months, and involve tools or processes with much quicker learning curves. 
A workflow experiment where you are forced to compare your own employees (who have been learning SAS for years) to high school graduates who begin learning during the experiment can have a lot of confounding factors. <br>
Nonetheless, if the product being tested has a very quick learning curve, then the cost of conducting a workflow experiment is much lower, and as I've mentioned, I can offer you such options. <br>


<br><br>
You need the students (or employees) in the experiment to be motivated and intellectually curious. If they are not, the experiment takes longer and costs more money. That is one reason, if you use high school graduates, they need a stipend. And if the employees have become too attached to a single brand name, then over the years they may become more reluctant to experiment with ideas not coming from that technology company. In my experience, SAS developers are very reluctant to try out new ideas not associated with the SAS brand name. This obviously will make a workflow experiment less efficient.


</body>
</html>
